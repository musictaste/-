### 推荐书籍

- 《编码：隐匿在计算机软硬件背后的语言》---入门
- 《计算机是怎么跑起来的？》--写的一般
- 《深入理解计算机系统》--比较难
- 语言：C JAVA **《C程序设计语言》(K&R) ** 《C Primer Plus》---这两本程序员必读
- 数据结构与算法： -- 毕生的学习 leetCode---程序员必读


    《Java数据结构与算法》(只有PDF，不更新了)  《算法》
    《算法导论》《计算机程序设计艺术》--难
- 操作系统：Linux内核源码解析 Linux内核设计与实现 30天自制操作系统
- 网络：机工《TCP/IP详解》卷一 翻译一般--强烈推荐
- 编译原理：机工 龙书--《编译原理》 《编程语言实现模式》
- 数据库：SQLite源码 Derby--JDK自带数据库
- 《深入理解linux内核》《深入理解计算机系统》 这两本书能夯实基础，应对大多数的面试

### CPU的制作过程

硅 -》 加入特殊元素 -》 半导体P/半导体N -》 PN结 -》 二极管 -》 场效应晶体管 -》 逻辑开关

### 汇编语言(机器语言)的执行过程

计算机通电 -> CPU读取内存中程序（电信号输入）->时钟发生器不断震荡通断电 ->推动CPU内部一步一步执行（执行多少步取决于指令需要的时钟周期）->计算完成->写回（电信号）->写给显卡输出（sout，或者图形）

### 问题：内存中的东西怎么发给显卡的

cpu发布指令  DMA机制（Direct Memory Access，直接存储器访问）

从内存中将数据通过总线发送到显卡，显卡中有缓冲区

每一个小缓冲区对应是显示器的一个像素

显示器有刷新率，40HZ，144HZ，不停的从显卡里读数据到屏幕

### 问题2:java的bytecode(二进制码)

bytecode是java的汇编语言

cpu机器码 和 java代码 的中间码

二进制码，通过不同系统的jvm，解释编译为不同操作的机器码

### CPU的基本组成

ALU + 寄存器(L0) + 内存(高速缓存L1/L2) + PC + MMU + CU

### 超线程：一个ALU对应多个 寄存器+PC  -》 4核8线程

8核16线程：可以同时执行8个线程，cpu可以读取16个线程

### 存储器的层次结构

![107](8FC6B7F241F74E4299D357703CC822BB)

### MESI 缓存一致性协议

缓存锁：MESI  MSI  MOSI   Synapse  FireFly   Dragon

![111](658BB95B9DA942BC84967E63384014A9)

### CPU的数据一致性实现=总线锁+ 缓存锁

总线锁会锁住总线，使得其他CPU甚至不能访问内存中其他的地址，效率极低

有些无法被缓存的数据或者跨越多个缓存行的数据依然使用总线锁

### cache line 

缓存行  64位  

缓存行越大，局部性空间效率越高，但读取时间慢
    缓存行越小，局部性空间效率越低，但读取时间快

### 缓存行对齐

缓存行对齐：对于有些特别敏感的数字，会存在线程高竞争的访问，**为了保证不发生伪共享**，可以使用缓存行对齐的编程方式

1.disruptor--cursor游标

JDK7中，很多采用long padding提高效率

采用disruptor的p1,p2,p3,p4,p5,p6,p7这种编程方式，可能只对于intel CPU管用
    
2.==JDK8，加入了@Contended注解（实验）需要加上：JVM -XX:-RestrictContended, 会根据底层的CPU自动缓存行对齐==

### 乱序执行

CPU为了提高执行执行效率，会在一条指令执行过程中，去同时执行另一条指令，前提是：两条指令没有依赖关系

cpu的计算速度，高于从内存中读取数据的速度

CPU到寄存器时间  比  到内存的时间  快100倍级

举例：单例DCL创建对象

创建对象分两步：第一步：分配内存，属性默认值；第二步：构造方法，属性默认值

![204](D7B633B9CE6F490393160E150EA9C8D2)

### 禁止乱序

CPU层面：Intel -> 原子指令（lock） 或者内存屏障(mfence(mixed) lfence sfence)

volatile的汇编命令：lock addl 0x0(加0)

synchronidez的汇编命令：lock cmpxchg

JVM层级：8个原子操作（lock/unlock/read/write/load/store/assing/use）  + hanppens-before原则 + 4个内存屏障 （LL LS SL SS）+ as-if-serial

volatile修饰对象，是锁定这个对象，不是内存地址

volatile的jvm实现：使用内存屏障，实现比较保守

synchronized：C/C++调用操作系统的同步机制

### 合并写 WCBuffer

提高写效率

4个字节

由于ALU速度太快，所以在写入L1的同时，写入一个WC Buffer，满了之后，再直接更新到L2

![210](30FA109A70B54D13B0BE5A7AD1F5A66E)

### NUMA

UMA（uniform memory accesss）:同一内存访问 多个cpu通过总线直接访问内存

Non Uniform Memory Access：非同一内存访问（就近访问原则），对于自己主板插槽上的内存具有优先访问权

ZGC - NUMA aware ,分配内存会优先分配该线程所在CPU的最近内存

![211](3BE5EB193FA6486193F00B2F51E2F424)

### 计算机启动过程（不重要）

通电 -> bios uefi 工作 -> 加电自检 -> 到硬盘固定位置加载bootloader到内存 -> 读取可配置信息 -> CMOS

BIOS：Basic Input Output System 基本输入输出系统

UEFI：Unified Extensible Firmware Interface统一可扩展固件接口，升级版

bootloaer：引导程序，在硬盘上的位置也是固定的，在硬盘的第一个扇区上（Master Boot Record）

CMOS：英文全称，互补氧化半导体

    配置信息在CMOS上，开机密码也在CMOS上，主板上有电池给CMOS供电
    0x7c00，操作系统启动的位置

![213](AE3130B0B07C4E2F9B18FC697D94A2E6)

### 操作系统的工作

管理硬件、管理软件

![215](7094C7A9660548BBAF88D6ECCF702A7F)

### 内核管理哪些内容、内核分类

cpu调度、内存管理、文件系统、应用管理/进程调度、中断处理/设备驱动

内核分为：

宏内核(PC phone)、

微内核(物联网  ioT  5G)、外核(阿里的多租户，request-based GC)、VMM

![216](666FA51484C74DDF9F59557B35817A28)

    
### 用户态和内核态

cpu不同的指令级别：cpu-CPL-0 1 2 3

linux内核跑在ring 0级， 用户程序跑在ring 3，对于系统的关键访问，需要经过kernel的同意，保证系统健壮性

    
### 问题：有一个系统，有很多请求，使用线程池，想要请求顺序执行，应该怎么做？ -> simpleThreadPool


### ==面试高频：进程和线程有什么区别？==

    答案：进程就是一个程序运行起来的状态，
    线程是一个进程中的不同的执行路径。
    
    专业（标准答案）：进程是OS分配资源的基本单位，
    线程是执行调度的基本单位。
    
    分配资源最重要的是：独立的内存空间，线程调度执行
    
    线程和进程最重要的区别（标准答案，最想听到的）：线程共享进程的内存空间，没有自己独立的内存空间

### ==面试题：线程和纤程的区别==：

    纤程(协程)：用户态的线程，线程中的线程，切换和调度不需要经过OS
    
    优势：1：占有资源很少 OS : 线程1M ，Fiber：4K 
    2：切换比较简单 
    3：启动数量多，启动很多个10W+（最重要的区别：并发量高）
    
    目前2020.3.22支持内置纤程的语言：Kotlin Scala Go Python(需要lib)... Java?
    
    （open jdk : loom分支支持纤程，目前没有合并到主分支；java14不支持纤程；java通过lib可以支持纤程）
    
    线程的切换发生在内核空间，切换比较重
    
    纤程的实现跟线程的实现差不多，不同处：是在用户态实现了纤程的调度和切换，
    相当于自己实现了内核的线程调度；线程是在内核态实现了纤程的调度和切换
    
    
==hotspot的实现：jvm级别的线程和操作系统级别的线程是一一对应的==

    JVM级别的线程也是重量级线程
    涉及到用户态和内核态的切换，以及在内核态开启一一对应的一个线程，需要在内核态分配独立的内存空间
    
==纤程 vs 线程池：很短的计算任务，不需要和内核打交道，并发量高！(10W+)==

![301](365B368C02D4405FA4753E0159139BC9)

### Fiber VS Thread （腾讯） 
纤程轻量级，线程重量级；纤程完成计算任务效率高一些

### 为什么线程效率低？（腾讯）  -》因为要跟内核态打交道

### 为啥和内核态打交道效率低呢？（腾讯） 

答案：80中断，跟内核态打交道是要经过系统调用的过程，

系统调用的过程要往寄存器里装很多东西，然后80中断产生调用，然后再拿结果；

跟用户态直接进行计算，然后取结果，肯定效率要低一些

### Java中对于纤程的支持：没有内置，盼望内置

利用Quaser库（不成熟）

纤程的运行，需要设置javaagent:（讲object的内存大小的时候，提到了agent代理）

怎么做到的呢？instrumentation这个类库做了一个agent代理，他把你的class做了内部改动，自动帮你生成了对应的栈，然后帮你管理栈之间的运行

### linux进程

linux中也称为task，是系统分配资源的基本单位

资源：独立的地址空间 内核数据结构（进程描述符。。。）全局变量 数据段。。

进程描述符：PCB（process control block）

linux中每一个进程，都一个内核数据结构，这个数据结构叫PCB，每个进程都有一个PCB，linux管理进程的时候把对应的信息记录在PCB中，PCB的大小是不固定的，

进程创建和启动：系统函数fork() exec()

从A中fork B的话，A称之为B的父进程

父进程A维护着子进程B、C、D的PCB数据结构

### 内核线程（了解）

内核启动之后经常需要做一些后台操作，这些有Kernal Thread来完成，只在内核空间运行

不要将内核线程跟启动一个新线程混淆

内核线程用于执行一些背后的操作，例如计时，定期清理垃圾

### 僵尸进程、孤儿进程(生产环境会用到)

**ps -ef | grep defunct**

父进程产生子进程后，会维护子进程的一个PCB结构，子进程退出，由父进程释放

==如果父进程没有释放，那么子进程成为一个僵尸进程==

**僵尸进程手工可以释放，使用wait()函数**

==僵尸进程会多余一个PCB的标识（只占PCB）==，**一般来说不会有影响；如果僵尸进程多了，需要手工释放（C语言编程时）**

**无法kill到僵尸进程，可以通过kill父进程来杀掉僵尸进程**


---


子进程结束之前，父进程已经退出

孤儿进程会成为init进程的孩子，由1号进程维护

**产生孤儿进程的影响不大**

### 进程调度

![310](F99C0743066E42F1ABFC4C0BAABE89E4)

进程类型：

    IO密集型：大部分时间等于等待IO
    CPU密集型：大部分时间用于闷头计算
    
进程优先级

    实时进程(急诊)  > 普通进程（门诊）（0-99）
    普通进程nice值（-20 到 19）
    
时间分配

    linux采用按优先级的CPU时间化
    其他系统多采用按优先级的时间片
    
默认调度策略：

> 实时 （急诊） 优先级分高低 - FIFO (First In First Out)，优先级一样 - RR（Round Robin 轮询）
> 
> 普通： CFS 完全公平调度算法

现在的操作系统，一般为抢占式多任务


内核进程调度器决定：该哪个进程运行？何时运行？运行多长时间？

> linux2.5 经典Unix O(1) 调度策略，偏向服务器，但对交互不友好(每个进程分配10毫秒)
> 
> linux 2.6.23 采用CFS 完全公平调度算法（completely fair scheduler）


==CFS：按优先级分配时间片的比例，记录每个进程的执行时间，如果有一个进程执行时间不到他应该分配的比例，优先执行==

> 举例：操作系统给进程A、B分配时间片，刚开始各占50%，各分配了0.5秒；其中进程A没有执行，把进程A占比的50%，分配给了进程B；
> 
> 第二次执行的时候，发现进程A，还没有执行原本分配给它的0.5秒的时间，那么优先执行进程A
> 


### 中断interrupt

 ==上下文切换是调度，不是中断；==
 
 #### 硬中断
 
 ![312](02FF11032A0640A5BEDD0E21BE5C662E)

==**中断：硬件跟操作系统内核打交道的一种机制**==

### 中断处理机制的实现细节（硬中断）：

> 按下键盘，通过中断控制器，通知CPU有一个键盘信号来了，
> 
> cpu会到一个固定的位置，找到执行程序，这个执行程序会通知kernel（也就是OS）有一个中断信号来了，
> 
> kernel会根据中断信号找到已经写好的 中断处理程序，
> 
> kernel（OS）会知道哪个程序在前台运行（office程序），然后os会把信号传递给office程序
> 
> 然后由office程序对键盘信号继续进行处理，这个处理就相当于我的应用程序已经接受到一个键被输入了

硬中断：硬件中的中断，例如键盘、网卡，时钟计时器、

### 软中断

软中断：**软件中的中断，任何系统调用都要打断内核，要调用内核的系统函数**

==软中断（80中断）= 系统调用==

### ==阿里面试，说明一下interrupt 80中断的执行过程（软中断面试会被问到）==：

> 软中断就是 80中断,也是 系统调用
> 
> 现在如果还有人问你80中断，你可以回答，现在是有sysenter原语的
> 
> 回答sysenter是有风险的，如果中小公司，他不知道，还以为你瞎说

> ==80中断具体的执行过程==
> 
> **1.系统调用：int 0x80 或者 sysenter原语，通过eax寄存器填入调用号**
> 
> 解释：int 0x80 是调用内核的系统函数，是老的操作系统和CPU采用的方式，C语言调用interrupt函数
> 
> sysenter是新的方式，操作系统和cpu在硬件层面直接支持，是汇编语言
> 
> sysenter原语也叫  更进一步
> 
> 这个还应用在内存映射，原来的内存映射是手工映射，现在是直接映射到机器上
> 
> 现在如果还有人问你80中断，你可以回答，现在是有sysenter的
>
> **2.参数通过bx cx dx si di传入内核，返回值通过eax返回**
> 
>  解释：bx cx dx si di是不同的寄存器名称，有几十个寄存器，内核函数就五个寄存器
> 
> 3.举例：java读网络 – jvm read() – c库read() - > 内核空间（int 0x80或sysenter原语） -> system_call() （系统调用处理程序） -> sys_read()
> 
> java读网络，通过JVM，调用C语言函数，到内核空间，通过系统调用（int 0x80或sysenter），通过eax寄存器填入调用号，返回值通过eax返回，然后一层层返回到应用程序

### 缺页中断

需要用到的页面，内存中没有，产生缺页异常（中断），由内核处理并加载

## 内存管理

### 现在的内存管理系统：虚拟地址 分页装入 软硬件结合寻址（由操作系统和MMU相互配合）

### 分页

内存不够用，内存撑爆

内存中分成固定大小的页框（4K），把程序（硬盘上）分成4K大小的块，用到哪一块，加载那一块，加载的过程中，如果内存已经满了，会把最不常用的一块放到swap分区（交换分区，硬盘实现）， 把最新的一块加载进来，这个就是著名的LRU算法

### LRU算法 LeetCode146题，头条要求手撕，阿里去年也要求手撕

方案一：数组：+时间戳，因为要遍历数组得到时间差最大的值，需要遍历整个数组，时间复杂度为O(n)

方案二：单向链表：每使用一次，在链表的尾节点加入节点，那么最不常用的节点就是头节点；查找节点的时间复杂度为O(n)、移动节点的时间复杂度都为O(1)

方案三：hash表+链表，linkedHashMap

    当左边指针指向右边的节点时，需要重新遍历整个链表，导致时间复杂度为O(n)

方案四：hash表+双向链表

### 虚拟内存（解决相互打扰问题）

1.DOS Win31 ... 互相干掉

2.为了保证互不影响 - 让进程工作在虚拟空间，程序中用到的空间地址不再是直接的物理地址，而是虚拟的地址，这样，A进程永远不可能访问到B进程的空间

虚拟空间多大呢？寻址空间 - 64位系统 2 ^ 64，比物理空间大很多 ，单位是byte

站在虚拟的角度，进程是独享整个系统 + CPU（每一个进程都虚拟的独占整个CPU）

内存映射：偏移量 + 段的基地址 = 线性地址 （虚拟空间）

线性地址通过 OS + MMU（硬件 Memory Management Unit 内存管理单元）

虚拟空间的格式是固定的：

    只读的代码和数据
    可读写的数据
    运行时堆
    共享库

![404](A051B660ED9247D5A07B91B923C8282D)

#### 为什么使用虚拟内存? 隔离应用程序+安全

    1.隔离应用程序
        每个程序都认为自己又连续可用的内存
        突破物理内存限制
        应用程序不需要考虑物理内存是否够用
    2.安全
        保护物理内存，不被恶意程序访问
        
### ZGC

颜色指针+ 读屏障

Colored Pointer + Load Barrier

算法叫做：Colored Pointer

**GC信息记录在指针上，不是记录在头部**，好处：immediate memory use**内存立即重用，效率马上提升**

**不支持32位，不支持指针压缩，不支持windows系统，只支持linux系统**

load Barrier根据指针颜色决定是否做一些事情

**42位指针（代表对象的地址） 寻址空间4T JDK13扩展成16T 目前为止最大16T 2^44**

==地址总线目前：48位（主板产商为了省成本），4位给颜色指针了，剩下可用的只有44位，也就是16T==

==颜色指针本质上包含了地址映射的概念==

![407](7DCEBDC0A4114095B681E7AA942A281C)

## 内核同步机制（面试不问，了解即可）

### 面试题：什么是分段锁

java.LongAddr

==分段锁：就是一条数据，分成很多段，同一时间一段数据只允许一个线程写；多段可以多个线程同时写==

==大厂考概念：分段锁==

==HashMap1.8之前提高效率用的就是分段锁；1.8之后呢？使用的是优化的synchronized 关键字同步代码块 和 cas操作了维护并发==

### hashMap、 hashTable、 和 ConcurrentHashMap的区别
    主要区别：
    （1）：实现线程安全的方式
    hashMap是线程不安全的，
    hashTable是线程安全的，实现线程安全的机制是使用Synchronized关键字修饰方法。
    ConcurrentHashMap
    <JDK1.7>，
    ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。
    <jdk1.8>
    使用的是优化的synchronized 关键字 和 cas操作了维护并发。
    （2）：底层数据结构：
    hashMap同hashTable；都是使用数组 + 链表结构
    ConcurrentHashMap
    <jdk1.7> ：使用 Segment数组 + HashEntry数组 + 链表
    <jdk1.8> ：使用 Node数组+链表+ 红黑树
    （3） ： 效率
    hashMap只能单线程操作，效率低下
    hashTable使用的是synchronized方法锁，若一个线程抢夺了锁，其他线程只能等到持锁线程操作完成之后才能抢锁操作
    《1.7》ConcurrentHashMap 使用的分段锁，如果一个线程占用一段，别的线程可以操作别的部分，
    《1.8》简化结构，put和get不用二次哈希，一把锁只锁住一个链表或者一棵树，并发效率更加提升。


### 关于同步理论的一些基本概念

==看并发编程的相关书籍，需要了解的基本概念，有助于更好的阅读==

•临界区（critical area）: **访问或操作共享数据的代码段** 

 简单理解：synchronized大括号中部分（原子性）

•竞争条件（race conditions）**两个线程同时拥有临界区的执行权**

•数据不一致：data unconsistency **由竞争条件引起的数据破坏**

•同步（synchronization）**避免race conditions**

•锁：**完成同步的手段**（门锁，门后是临界区，只允许一个线程存在）
 **上锁解锁必须具备原子性**

•原子性（象原子一样不可分割的操作）

•有序性（禁止指令重排）

•可见性（一个线程内的修改，另一个线程可见）

互斥锁(轻量级锁、CAS) 排他锁(读写锁-写) 共享锁（读写锁-读） 分段锁（LongAddr）

### 内核同步常用方法（linux内核）

了解一下Linux内核的同步，用于理解Java的同步机制

1.**原子操作 – 内核中类似于AtomicXXX**，位于<linux/types.h>
**一般是cmpxchg汇编指令**

2.**自旋锁 – 内核中通过汇编支持的cas**，位于<asm/spinlock.h>

3.**读-写自旋** – 类似于ReadWriteLock，可同时读，只能一个写
 读的时候是共享锁，写的时候是排他锁

4.**信号量** – 类似于Semaphore(PV操作=down up操作=占有和释放）

 **重量级锁，线程会进入wait，适合长时间持有的锁情况（这里讲的是Linux）**
 
 java的Semaphore采用的是CAS

5.**读-写信号量** – downread upread downwrite upwrite

 **（多个写，可以分段写，比较少用）(分段锁）**
 
 6.**互斥体(mutex) – 特殊的信号量（二值信号量）**

**这才是我们平时理解的锁，互斥锁，值为0和1，就是一种特殊的Semaphore**

**java的Synchronized就是互斥锁**

7.**完成变量 – 特殊的信号量（A发出信号给B，B等待在完成变量上）**

**vfork() 在子进程结束时通过完成变量叫醒父进程 类似于(Latch--countdownLatch)**

vfork()效率特别高

==java的AIO底层(linux)用的是epoll，不是完成变量模式；windows系统使用完成变量模式(vfork)实现==

8.**BKL：大内核锁（早期，现在已经不用）**

==9.顺序锁（linux内核2.6，新增的）： – 线程可以挂起的读写自旋锁==

 **序列计数器（从0开始，写时增加(+1)，写完释放(+1)，读前发现单数，说明有写线程，等待，读前读后序列一样，说明没有写线程打断**）
 
**读线程采用的CAS，写线程不是排它锁（不同于读写锁的写操作是排他的）**

10.**禁止抢占 – preempt_disable()**

**只有内核才有这样的操作，执行过程不允许任何人打断我；不需要同步，**

==一般用于处理中断==

一个数据只有一个CPU在用，所以没有必要上锁

**单核CPU也是可以运行多线程的**

==用于单核CPU多线程的优化==

11.内存屏障 – 见volatile

